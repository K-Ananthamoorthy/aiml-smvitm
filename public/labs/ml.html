<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="google-adsense-account" content="ca-pub-3267548468157685">
    <title>ML Lab Programs</title>
    <link rel="icon" href="/media/logo_aiml.png" type="image/x-icon">
    <!-- Bootstrap CSS -->
    <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet">
    <!-- Font Awesome CSS for icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <!-- Highlight.js CSS for syntax highlighting -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css">
    <style>
        body {
            background-color: #343a40;
            color: #ffffff;
            padding-top: 56px; /* Adjusted for the fixed navbar */
        }
        .program-section {
            margin-top: 20px;
        }
        .program-card {
            border: 1px solid #dee2e6;
            border-radius: 10px;
            margin-bottom: 20px;
            background-color: #ffffff;
            color: #343a40;
            position: relative;
        }
        .copy-icon {
            position: absolute;
            top: 10px;
            right: 10px;
            font-size: 20px;
            color: #007bff;
            cursor: pointer;
        }
        .navbar {
            background-color: #007bff;
            color: white;
        }
        .footer {
            background-color: #343a40;
            color: #ffffff;
            text-align: center;
            padding: 5px;
            position: fixed;
            bottom: 0;
            width: 100%;
            opacity: 0.9;
            border-top: 1px solid #007bff;
        }
        .footer-icons {
            font-size: 24px;
            margin: 0 10px;
            color: #007bff;
            transition: color 0.3s ease-in-out;
        }
        .footer-icons:hover {
            color: #ffffff;
        }
        .dark-toast {
            position: fixed;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            background-color: #343a40;
            color: #ffffff;
            padding: 15px;
            border-radius: 10px;
            z-index: 1000;
            display: none;
        }
    </style>
</head>
<body>

<nav class="navbar navbar-expand-lg navbar-dark fixed-top">
    <a class="navbar-brand" href="/">ML Lab</a>
</nav>

<div class="container-fluid">
    <h2 class="text-center mt-4">ML Lab Programs</h2>

   <!-- Program 5-->
   <div class="row" id="program-5">
    <div class="col-md-12">
        <div class="card program-card">
            <i class="fas fa-copy copy-icon" onclick="copyToClipboard('program-5')"></i>
            <div class="card-body">
                <h5 class="card-title">program 5-K MEANS</h5>
                <pre><code class="python" id="program-5">
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn import preprocessing as p
from sklearn.mixture import GaussianMixture as GMM
import sklearn.metrics as sm
import pandas as pd
import numpy as np
from sklearn.datasets import load_iris

# Load the Iris dataset
iris = load_iris()
iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)
iris_df['Targets'] = iris.target

# Features and target
x = iris_df[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']]
y = iris_df[['Targets']]

# KMeans clustering
model = KMeans(n_clusters=3)
model.fit(x)

# Standardize the features
scaler = p.StandardScaler()
scaler.fit(x)
xs = scaler.transform(x)

# GMM clustering
gmm = GMM(n_components=3)
gmm.fit(xs)
y_gmm = gmm.predict(xs)

# Plotting
plt.figure(figsize=(10,10))
colormap = np.array(['red', 'lime', 'blue'])

# Real classification
plt.subplot(2, 2, 1)
plt.scatter(x['petal length (cm)'], x['petal width (cm)'], c=colormap[y['Targets']], s=40)
plt.title('Real Classification')
plt.xlabel('petal length (cm)')
plt.ylabel('petal width (cm)')

# KMeans clustering
plt.subplot(2, 2, 2)
plt.scatter(x['petal length (cm)'], x['petal width (cm)'], c=colormap[model.labels_], s=40)
plt.title('K Means Clustering')
plt.xlabel('petal length (cm)')
plt.ylabel('petal width (cm)')

# GMM classification
plt.subplot(2, 2, 3)
plt.scatter(x['petal length (cm)'], x['petal width (cm)'], c=colormap[y_gmm], s=40)
plt.title('GMM Classification')
plt.xlabel('petal length (cm)')
plt.ylabel('petal width (cm)')

plt.show()

# Evaluation of KMeans clustering
print('Evaluation of KMeans Clustering')
print('RandIndex: %f' % sm.adjusted_rand_score(y['Targets'], model.labels_))
print('Homogeneity: %f' % sm.homogeneity_score(y['Targets'], model.labels_))
print('Completeness: %f' % sm.completeness_score(y['Targets'], model.labels_))
print('V-Measure: %f' % sm.v_measure_score(y['Targets'], model.labels_))

# Evaluation of GMM clustering
print('Evaluation of GMM with ground truth classification of iris dataset')
print('RandIndex: %f' % sm.adjusted_rand_score(y['Targets'], y_gmm))
print('Homogeneity: %f' % sm.homogeneity_score(y['Targets'], y_gmm))
print('Completeness: %f' % sm.completeness_score(y['Targets'], y_gmm))
print('V-Measure: %f' % sm.v_measure_score(y['Targets'], y_gmm))


                </code></pre>
            </div>
        </div>
    </div>
</div>


 
    <!-- Program 6-->
    <div class="row" id="program-6">
        <div class="col-md-12">
            <div class="card program-card">
                <i class="fas fa-copy copy-icon" onclick="copyToClipboard('program-6')"></i>
                <div class="card-body">
                    <h5 class="card-title">program 6-ANN</h5>
                    <pre><code class="python" id="program-6">
import numpy as np

# Input and output data
X = np.array(([2, 9], [1, 5], [3, 6]), dtype=float)
y = np.array(([92], [86], [89]), dtype=float)

# Normalize data
X = X / np.amax(X, axis=0) # Maximum of X array longitudinally
y = y / 100

# Training settings
epoch = 5000 # Setting training iterations
lr = 0.1 # Setting learning rate
inputlayer_neurons = 2 # Number of features in dataset
hiddenlayer_neurons = 3 # Number of hidden layer neurons
output_neurons = 1 # Number of output neurons

# Weight and bias initialization
wh = np.random.uniform(size=(inputlayer_neurons, hiddenlayer_neurons))
bh = np.random.uniform(size=(1, hiddenlayer_neurons))
wout = np.random.uniform(size=(hiddenlayer_neurons, output_neurons))
bout = np.random.uniform(size=(1, output_neurons))

# Activation function
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

# Derivative of sigmoid function
def derivatives_sigmoid(x):
    return x * (1 - x)

# Training algorithm
for i in range(epoch):
    # Forward propagation
    hinp1 = np.dot(X, wh)
    hinp = hinp1 + bh
    hlayer_act = sigmoid(hinp)

    outinp1 = np.dot(hlayer_act, wout)
    outinp = outinp1 + bout
    output = sigmoid(outinp)

    # Backpropagation
    EO = y - output
    outgrad = derivatives_sigmoid(output)
    d_output = EO * outgrad

    EH = d_output.dot(wout.T)
    hiddengrad = derivatives_sigmoid(hlayer_act)
    d_hiddenlayer = EH * hiddengrad

    # Updating weights and biases
    wout += hlayer_act.T.dot(d_output) * lr
    wh += X.T.dot(d_hiddenlayer) * lr

# Output results
print("Input: \n" + str(X))
print("Actual Output: \n" + str(y))
print("Predicted Output: \n" + str(output))


                    </code></pre>
                </div>
            </div>
        </div>
    </div>



<!-- Program 7-->
    <div class="row" id="program-7">
        <div class="col-md-12">
            <div class="card program-card">
                <i class="fas fa-copy copy-icon" onclick="copyToClipboard('program-7')"></i>
                <div class="card-body">
                    <h5 class="card-title">program 7 - Naive baysed classification</h5>
                    <pre><code class="python" id="program-7">
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score

# Load dataset
msg = pd.read_csv('document.csv', names=['message', 'label'])
print("Total Instances of Dataset: ", msg.shape[0])

# Map labels to numerical values
msg['labelnum'] = msg.label.map({'pos': 1, 'neg': 0})

# Features and labels
X = msg.message
y = msg.labelnum

# Split dataset into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Vectorize text data
count_v = CountVectorizer()
X_train_dm = count_v.fit_transform(X_train)
X_test_dm = count_v.transform(X_test)

# Train a classifier
clf = MultinomialNB()
clf.fit(X_train_dm, y_train)

# Predict on test data
pred = clf.predict(X_test_dm)

# Print predictions
for doc, p in zip(X_test, pred):
    sentiment = 'pos' if p == 1 else 'neg'
    print(f"{doc} -> {sentiment}")

# Calculate and print accuracy metrics
print('Accuracy Metrics: \n')
print('Accuracy:', accuracy_score(y_test, pred))
print('Recall:', recall_score(y_test, pred))
print('Precision:', precision_score(y_test, pred))
print('Confusion Matrix: \n', confusion_matrix(y_test, pred))



                    </code></pre>
                </div>
            </div>
        </div>
    </div>



    
  <!-- Program 9-->
  <div class="row" id="program-9">
    <div class="col-md-12">
        <div class="card program-card">
            <i class="fas fa-copy copy-icon" onclick="copyToClipboard('program-9')"></i>
            <div class="card-body">
                <h5 class="card-title">program 9-Decision Tree</h5>
                <pre><code class="python" id="program-9">

import pandas as pd
from math import log
from collections import Counter
from pprint import pprint

df_tennis = pd.read_csv('tennis.csv')

def entropy(probs):
    return sum([-prob * log(prob, 2) for prob in probs])

def entropy_of_list(a_list):
    cnt = Counter(x for x in a_list)
    num_instances = len(a_list) * 1.0
    probs = [x / num_instances for x in cnt.values()]
    return entropy(probs)

def information_gain(df, split_attribute_name, target_attribute_name):
    df_split = df.groupby(split_attribute_name)
    nobs = len(df.index) * 1.0
    df_agg_ent = df_split.agg({target_attribute_name: [entropy_of_list, lambda x: len(x) / nobs]})[target_attribute_name]
    df_agg_ent.columns = ['Entropy', 'PropObservations']
    new_entropy = sum(df_agg_ent['Entropy'] * df_agg_ent['PropObservations'])
    old_entropy = entropy_of_list(df[target_attribute_name])
    return old_entropy - new_entropy

def id3(df, target_attribute_name, attribute_names, default_class=None):
    cnt = Counter(x for x in df[target_attribute_name])
    if len(cnt) == 1:
        return next(iter(cnt))
    elif df.empty or (not attribute_names):
        return default_class
    else:
        default_class = max(cnt.keys())
        gainz = [information_gain(df, attr, target_attribute_name) for attr in attribute_names]
        index_of_max = gainz.index(max(gainz))
        best_attr = attribute_names[index_of_max]
        tree = {best_attr: {}}
        remaining_attribute_names = [i for i in attribute_names if i != best_attr]
        for attr_val, data_subset in df.groupby(best_attr):
            subtree = id3(data_subset, target_attribute_name, remaining_attribute_names, default_class)
            tree[best_attr][attr_val] = subtree
        return tree

attribute_names = list(df_tennis.columns)
attribute_names.remove('PlayTennis')

tree = id3(df_tennis, 'PlayTennis', attribute_names)
print("\n\nThe Resultant Decision Tree is: \n")
pprint(tree)

                </code></pre>
            </div>
        </div>
    </div>
</div>

    <!-- Program 10-->
    <div class="row" id="program-10">
        <div class="col-md-12">
            <div class="card program-card">
                <i class="fas fa-copy copy-icon" onclick="copyToClipboard('program-10')"></i>
                <div class="card-body">
                    <h5 class="card-title">program 10- SVM</h5>
                    <pre><code class="python" id="program-10">
import pandas as pd
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

iris = datasets.load_iris()
X = iris.data
y = iris.target

df = pd.DataFrame(data=iris.data, columns=iris.feature_names)
df['target'] = iris.target
print(df.head())

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

svm_model = SVC(kernel='linear')
svm_model.fit(X_train, y_train)

y_pred = svm_model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy * 100:.2f}%')
print('\nClassification Report:')
print(classification_report(y_test, y_pred, target_names=iris.target_names))
print('\nConfusion Matrix:')
conf_matrix = confusion_matrix(y_test, y_pred)
sns.heatmap(conf_matrix, annot=True, cmap='Blues', xticklabels=iris.target_names, yticklabels=iris.target_names)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

                    </code></pre>
                </div>
            </div>
        </div>
    </div>


<div class="footer">
    <a href="#" target="_blank" rel="noopener noreferrer">
        <span class="footer-icons"><i class="fab fa-github"></i></span>
    </a>
</div>

<div id="dark-toast" class="dark-toast">
    <div class="toast-body">Copied to clipboard!</div>
</div>

<!-- Bootstrap JS and Popper.js -->
<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.0.7/dist/umd/popper.min.js"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>
<!-- Highlight.js for syntax highlighting -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<script>
    function copyToClipboard(elementId) {
        var copyText = document.getElementById(elementId);
        var textArea = document.createElement("textarea");
        textArea.value = copyText.innerText;
        document.body.appendChild(textArea);
        textArea.select();
        document.execCommand('copy');
        document.body.removeChild(textArea);

        var toast = document.getElementById('dark-toast');
        toast.style.display = 'block';
        toast.innerText = 'Copied to clipboard!';

        setTimeout(function () {
            toast.style.display = 'none';
        }, 2000);
    }

    function copyProgramFromUrl() {
        var url = window.location.href;
        var programNumber = url.match(/ml(\d+)$/);
        if (programNumber) {
            var programId = 'program' + programNumber[1];
            copyToClipboard(programId);
        }
    }

    document.addEventListener('DOMContentLoaded', function() {
        copyProgramFromUrl();
    });
</script>


</body>
</html>
